{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from dataloader import ArcTrainDataset, ArcEvaluationDataset, ArcTestDataset, FlattenTrainDataset\n",
    "from model import OfflineEncoderDecoder, OnlineAttentionSolver, count_parameters\n",
    "\n",
    "def train_one_epoch(epoch_index, tb_writer, training_loader, optimizer, device):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for idx, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, outputs = data\n",
    "        inputs = torch.tensor(inputs, device=device)\n",
    "        outputs = torch.tensor(outputs, device=device)\n",
    "        n_inputs = inputs.size(0)\n",
    "        n_outputs = outputs.size(0)\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        input_preds = model(inputs)\n",
    "        output_preds = model(outputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = input_latent_loss(input_preds, inputs) / n_inputs \\\n",
    "            + output_latent_loss(output_preds, outputs) / n_outputs\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if idx % 10 == 9:\n",
    "            last_loss = running_loss / 10 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(idx + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + idx + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss\n",
    "\n",
    "\n",
    "arc_train_path = './data/arc-agi_training_challenges.json'\n",
    "arc_train_sol_path = './data/arc-agi_training_solutions.json'\n",
    "\n",
    "arc_eval_path = './data/arc-agi_evaluation_challenges.json'\n",
    "arc_eval_sol_path = './data/arc-agi_evaluation_solutions.json'\n",
    "\n",
    "arc_test_path = './data/arc-agi_test_challenges.json'\n",
    "\n",
    "# %%\n",
    "arc_train_dataset = FlattenTrainDataset(fpath=arc_train_path, apply_onehot=True)\n",
    "arc_evaluate_dataset = ArcEvaluationDataset(\n",
    "    test_fpath=arc_train_path,\n",
    "    solution_fpath=arc_train_sol_path,\n",
    "    apply_onehot=True\n",
    ")\n",
    "# %%\n",
    "device = torch.device('cpu')\n",
    "model = OfflineEncoderDecoder(channels=[11,11,11], latent_dim=128)\n",
    "model.to(device)\n",
    "\n",
    "# %%\n",
    "### Test\n",
    "# x,y = arc_train_dataset[0]\n",
    "# x_preds = model(torch.tensor(x, dtype=torch.float32))\n",
    "arc_train_loader = torch.utils.data.DataLoader(arc_train_dataset, batch_size=8)\n",
    "# %%\n",
    "\n",
    "# learning for latent dimension\n",
    "input_latent_loss = torch.nn.MSELoss()\n",
    "output_latent_loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/arc_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(1):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "    model.train()\n",
    "    avg_loss = train_one_epoch(\n",
    "        epoch_number,\n",
    "        writer,\n",
    "        training_loader=arc_train_loader,\n",
    "        optimizer=optimizer,\n",
    "        device=device)\n",
    "    print(avg_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
